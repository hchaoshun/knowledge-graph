# 机器学习
机器学习知识汇总

- [ROC曲线](https://zh.wikipedia.org/wiki/ROC%E6%9B%B2%E7%BA%BF)
- [机器学习中常常提到的正则化到底是什么意思？](https://www.zhihu.com/question/20924039)
- [如何简单形象又有趣地讲解神经网络是什么？](https://www.zhihu.com/question/22553761)
- [反向传播算法](https://developers-dot-devsite-v2-prod.appspot.com/machine-learning/crash-course/backprop-scroll?hl=zh-cn)
- [反向传播算法公式推导](https://zhuanlan.zhihu.com/p/39711038)
- [如何直观地解释 backpropagation 算法？](https://www.zhihu.com/question/27239198/answer/89853077)
- [What is the difference between linear regression and logistic regression?](https://stackoverflow.com/questions/12146914/what-is-the-difference-between-linear-regression-and-logistic-regression)
- [线性回归与逻辑回归的区别](https://blog.csdn.net/likewind1993/article/details/84196135)
- [Understanding Feature Importance in Machine Learning](https://builtin.com/data-science/feature-importance#:~:text=Feature%20importance%20is%20a%20step,to%20predict%20a%20certain%20variable.)

## Deep Learning
- [Why Deep Learning Uses GPUs](https://deeplizard.com/learn/video/6stDhEA0wFQ)
- [深度学习中Dropout原理解析](https://zhuanlan.zhihu.com/p/38200980)
- [动量梯度下降法Momentum](https://terrifyzhao.github.io/2018/02/16/%E5%8A%A8%E9%87%8F%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95Momentum.html)
- [深度学习优化算法解析(Momentum, RMSProp, Adam)](https://blog.csdn.net/willduan1/article/details/78070086)
- [Batch Normalization原理与实战](https://zhuanlan.zhihu.com/p/34879333)
- [残差网络解决了什么，为什么有效？](https://www.cvmart.net/community/detail/3487)

### 注意力Attention
- [一文看懂 Attention](https://easyaitech.medium.com/%E4%B8%80%E6%96%87%E7%9C%8B%E6%87%82-attention-%E6%9C%AC%E8%B4%A8%E5%8E%9F%E7%90%86-3%E5%A4%A7%E4%BC%98%E7%82%B9-5%E5%A4%A7%E7%B1%BB%E5%9E%8B-e4fbe4b6d030)
- [深度学习中的注意力机制](https://blog.csdn.net/tg229dvt5i93mxaq5a6u/article/details/78422216)
- [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)

## LLM
- [一文读懂AI大模型发展历程](http://www.impcia.net/artificial/details_79.html)
- [解读大模型（LLM）的token](https://mp.weixin.qq.com/s/8jJVA7_6XSNo6xyG-OxovA)
- [从 MLOps 到 LMOps 的关键技术嬗变](https://mp.weixin.qq.com/s/dfGVC7yCYr8DHw_Otk8J8Q)
- [Andrej Karpathy《大模型快速入门》（全文）](https://mp.weixin.qq.com/s/aCbe9LU6NyPUS-Z1Vv90iw)
- [CUDA编程入门极简教程](https://zhuanlan.zhihu.com/p/34587739)
- [Introduction to Weight Quantization](https://mlabonne.github.io/blog/posts/Introduction_to_Weight_Quantization.html)
- [RLHF何以成LLM训练关键](https://www.51cto.com/article/767048.html)
- [What Are LLM Agents ? An Overview of Their Capabilities](https://gptpluginz.com/llm-agents/)
- [State of GPT：大神Andrej揭秘OpenAI大模型原理和训练过程](https://mp.weixin.qq.com/s?__biz=MzIxODUzNTg2MA==&mid=2247485342&idx=1&sn=770152ca8a00f2e3d87ed2a09e131e11)
- [LLaMA 2 - Every Resource you need](https://www.philschmid.de/llama-2)
- [聊一聊大模型幻觉：起因、评估及缓解策略探索](https://mp.weixin.qq.com/s/c7CCsB18HmuB3G1WnAHwdQ)
- [大模型思维链（Chain-of-Thought）技术原理](https://www.zhihu.com/tardis/zm/art/629087587?source_id=1003)
- [LoRA: Efficient Model Fine-tuning](https://chat.openai.com/share/c5ef0067-3e88-409e-b574-5295981be369)
- [Tokenizers](https://huggingface.co/learn/nlp-course/en/chapter2/4)

## 推理优化
### LLM
- [CPU 和 GPU 的区别是什么？](https://www.zhihu.com/question/19903344/answer/96081382)
- [图解大模型推理优化之 KV Cache](https://mp.weixin.qq.com/s/6q2LmwoFG2LcN0iHoZjjqw)
- [vLLM PagedAttention](https://blog.vllm.ai/2023/06/20/vllm.html)
- [模型量化综述及应用](https://bbs.huaweicloud.com/blogs/293961)


### TensorRT
- [Speeding Up Deep Learning Inference Using TensorFlow, ONNX, and NVIDIA TensorRT](https://developer.nvidia.com/blog/speeding-up-deep-learning-inference-using-tensorflow-onnx-and-tensorrt/)
- [Accelerating Deep Learning Inference for Machine Vision](https://medium.com/@fractal.ai/accelerating-deep-learning-inference-for-machine-vision-using-onnx-and-tensorrt-d43351680345)

## 机器学习算法
- [决策树](https://easyai.tech/ai-definition/decision-tree/#:~:text=%E9%A2%84%E6%B5%8B%E6%97%B6%EF%BC%8C%E5%9C%A8%E6%A0%91%E7%9A%84,%E6%80%9D%E7%BB%B4%EF%BC%8C%E6%9C%89%E7%9D%80%E5%B9%BF%E6%B3%9B%E7%9A%84%E5%BA%94%E7%94%A8%E3%80%82)
- [随机森林 – Random forest](https://easyai.tech/ai-definition/random-forest/)
- [GBDT：梯度提升决策树](https://www.jianshu.com/p/005a4e6ac775)
- [Gradient Boosted Decision Tree — Clearly Explained](https://medium.com/@ruchi.awasthi63/gradient-boosted-decision-tree-clearly-explained-bd1d8c7d9923)
- [机器学习 | 详解GBDT梯度提升树原理，看完再也不怕面试了](https://zhuanlan.zhihu.com/p/169568445)
- [KNN算法](https://blog.csdn.net/saltriver/article/details/52502253)
- [理解 product quantization 算法](http://vividfree.github.io/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/2017/08/05/understanding-product-quantization)
## 神经网络
- [神经网络讲解视频](https://space.bilibili.com/88461692/channel/detail?cid=26587)
- [神经网络浅讲：从神经元到深度学习](https://www.cnblogs.com/subconscious/p/5058741.html)
- [一文弄懂神经网络中的反向传播法——BackPropagation](https://www.cnblogs.com/charlotte77/p/5629865.html)
- [详解深度学习中的梯度消失、爆炸原因及其解决方法](https://zhuanlan.zhihu.com/p/33006526)

## TensorFlow

- [Simple Linear Regression Using TensorFlow and Keras](https://www.machinelearningmindset.com/linear-regression-with-tensorflow/)
- [Top-5 Painless Data Augmentation Techniques With TensorFlow](https://www.machinelearningmindset.com/data-augmentation-with-tensorflow/#dataset)
- [An Advanced Example of the Tensorflow Estimator Class](https://towardsdatascience.com/an-advanced-example-of-tensorflow-estimators-part-1-3-c9ffba3bff03)
- [探索TensorFlow的运行原理：TensorFlow是如何运行的？](https://zhuanlan.zhihu.com/p/629303544)
- [tensorflow estimator](https://chat.openai.com/share/6c4acce5-0ee1-4708-b38c-a12ffb2f6a64)

## 强化学习
- [强化学习-Reinforcement learning | RL](https://easyai.tech/ai-definition/reinforcement-learning/)
